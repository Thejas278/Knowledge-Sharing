 Using core java we can develp desktop applications or standalone applications
2 types of stand alone applications
	1.GUI-Graphica User Interface- eg desktop applications or calculator
	2.CUI-Character User Inerface - Applicatios which are run using the command prompt also knows as console based applications.

Using advanced java we can develop web applications- applications which provide service in web
Advanced Java There are 3 things

1.JDBC
2.Servlets
3.JSp's

There are 3 editions of Java according to Sun Micro or Oracle

	1. Java Standard Edition(J2SE)-JDBC
	2.Java Enterprise Edition(J2EE)-Servlets and Jsp's,EJB,JPA etc
	3.Java Micro Edition(J2ME)-Used for mobile,embeded applications like tv remote
Advanced Java has
	JDBC
	Servlet
	JSP

	JDBC- Is used to connect to database

		JDBC is a specification defined by java vendor, it is implemented by database vendors

		Driver are the implementations of JDBC

		JDBC Driver(Transalator)- Converts the JDBC native calls to native database calls(Converts java calls into database 			specifc calls and vice versa)

		Connector- Provides the connection to database(DriverManager.getConnection or DataSource.getConnection)

		DiverManger.getConnection will return a new connection everytime we call it

		DatSource.getConnection- We will get connection Object from  connection poll

		StatmentObject- Which will send the query to database and bring the resut from database.

		Resultset - Is the result which the database gives

		Steps for JDBC

		1.Load and register the driver( eg Class.forName(ClassName)- this method can be used to load any java class)
		2.Establish the connection.
		3.Use statement object
		4.Retrive the resultset
		5.Close the connection

Proxies are used for
	1.Security
	2.Caching
	3.Reverse Proxy is used for load balancing
	
Forward Proxy vs Reverse Proxy

Forward Proxy sits in between the client machine and the internet will be infront of client,when the client makes the request in the internet, forward proxy will act as a middle man and talks to webserver on bhalf of client.
Forward Proxy will protects the client's online identity only the proxies ip address is visible.
Forward proxy can be used to block certain websites by companies or schools as well.

Reverse Proxy sits in between the webserver and the internet, It will intercept the client request and talks to webserver on behalf of client
Reverse Proxy can be used to protect the webserver identity only reverse proxies ip will be visible
It can be used for loadbalancing
They can also be used for caching some contents

TCP-Transport Control Protool or Transmission Control Protocol.

	It is a standard protocol that allows data to be exchanged between devices on a network. It is a basic standard that defines how 	data is delivered over the internet.
	It is like a telephone line and germen and french are the protcols like HTTP,FTP
	Webserver and webclients use HTTP protocol

Difference between web server and application server
	Web Server is mostly designed to serve static content, though most Web Servers have plugins to support scripting languages like Perl, PHP, ASP, JSP etc. through which these servers can generate dynamic HTTP content.	

	Webservers will be listening to a port which is assgned to them by the operating system, when ever that port gets any request , it will be redirected to that web server

	Most of the application servers have Web Server as integral part of them, that means App Server can do whatever Web Server is capable of. Additionally App Server have components and features to support Application level services such as Connection Pooling, Object Pooling, Transaction Support, Messaging services etc.
	
	As web servers are well suited for static content and app servers for dynamic content, most of the production environments have web server acting as reverse proxy to app server. That means while servicing a page request, static contents (such as images/Static HTML) are served by web server that interprets the request. Using some kind of filtering technique (mostly extension of requested resource) web server identifies dynamic content request and transparently forwards to app server

	Example of such configuration is Apache Tomcat HTTP Server and Oracle (formerly BEA) WebLogic Server. Apache Tomcat HTTP Server is Web Server and Oracle WebLogic is Application Server.

Webserver support web applications
Application server supports enterprise level application.

	WebServers support static contents like Servlets,JSP,HTML it does not support EJB's

	Every Application server will have webserver but if the provided web server is not enough then we need seperare webserver server. 

How a web server works
A web server is technology that hosts a website’s code and data. When you enter a URL in your browser, the URL is actually the address identifier of the web server.

Your browser and web server communicate as follows:

The browser uses the URL to find the server’s IP address
The browser sends an HTTP request for information
The web server communicates with a database server to find the relevant data
The web server returns static content such as HTML pages, images, videos, or files in an HTTP response to the browser
The browser then displays the information to you
A website that hosts static content like blogs, header images, or articles can run on a web server. However, most websites and web applications are much more interactive and require an application server.

How an application server works
An application server extends the capabilities of a web server by supporting dynamic content generation, application logic, and integration with various resources. It provides a runtime environment where you can run application code and interact with other software components, like messaging systems and databases. It uses business logic to transform data more meaningfully than a web server.

When you attempt to access interactive content on a website, the process works as follows:

The browser uses the URL to finds the server’s IP address
The browser sends an HTTP request for information
The web server transfers the request to the application server
The application server applies business logic and communicates with other servers and third-party systems to fulfill the request
The application server renders a new HTML page and returns it as a response to the web server
The web server returns the response to the browser
The browser displays the information to you
To use the example of an ecommerce website, when you add items to your cart, or check out items, you interact with the application server.

Key differences: web server vs. application server
Web and application servers have several key differences that set them apart.

Tasks covered
A web server hosts websites and delivers responses to simple requests. Web servers also log server activity and allow server-side scripting.

On the other hand, application servers have a more complex set of tasks. Application servers handle business logic to generate dynamic content by connecting with enterprise systems, services, and databases.

Protocols used
The primary protocol web servers use is the HTTP protocol. However, different web servers also support FTP and Simple Mail Transfer Protocol (SMTP). These two protocols facilitate file storage and transfer as well as email.

In addition to the protocols that web servers use, application servers use additional communication protocols to communicate with other software components. For example, they may use remote method invocation (RMI) and remote procedure call (RPC).

Content types
Web servers mostly deliver static content. Static content is content that a server doesn’t need to modify or process before delivering. For example, image files (like PNG, GIF, and JPEG), downloadable documents (PDFs), videos, and HTML files are all static content. 

Application servers mostly deliver dynamic content. Dynamic content is content that changes based on how the user interacts with it. For example, dynamically generated reports, customized data representations, personalized UIs, database results, and processed HTML are all dynamic content.

Multithreading
Threads on a server are separate pathways of operation that enable the concurrent processing of tasks. In multithreading, the server creates and runs multiple threads simultaneously, and each handles a separate task or part of a task. Support for multithreading helps to deliver web content faster while managing more web traffic.

Most web servers don’t support multithreading. Web servers place each new connection request in a queue and use an event loop to monitor new entries and exits from the queue. To improve efficiency, the server processes requests by using non-blocking I/O and callbacks. Non-blocking operations and event-driven architecture allow web servers to handle concurrent connections.

Application servers use multithreading to provide high scalability and efficiency. If a request requires external resources, the application server uses separate threads to cover those interactions. It can process multiple threads at once, serving many client interactions in parallel. 

How do application servers and web servers work together?
Application servers and web servers work together to handle client requests and deliver the correct content to the user. The web server always receives a new request first. If it can produce the information itself, it does so and sends back an HTTP response. It also checks that the data the user requested isn’t already in its cache.

If the web server can’t access the content the user requires, it forwards the request to the application server. The application server processes data and uses business logic to provide the correct information. It then passes the request back to the web server, which passes it on to the user. In certain architectures, you can also configure application servers to handle HTTP requests by themselves.

What is a servlet
Servlet stands for Server Component
resides on server and run on server and output will be on the client page
Servlets are used to create a dynamic contents.

There are 2 ways to call a servlet from another servlet
	1.Request Dispatcher- Client will not come to know if we go from one servlet to another(eg if we take our client from our website to paymentgateway like paypal they should know that they have been redirected)
		RequestDispatcher dis=req.getRequestDispatcher("st");
		dis.forward(req, res);
	2.SendRedirect- Here Client will come to know
		res.sendRedirect("sq");

** Life Cycle of Servlet
		The servlet is initialized by calling the init() method.

		The servlet calls service() method to process a client's request.

		The servlet is terminated by calling the destroy() method.

		Finally, servlet is garbage collected by the garbage collector of the JVM.

** Instead of adding all the servlets in web.xml we can also use a annotation known as @WebServlet("/addition") on top of the servlet class

JSP-Java Server Pages
	we can write java code inside html
	Internally every jsp page is converted into a servlet with class name same as the jsp file name and what ever we have defined inside the scriplet tag will go inside the service method(<%  java code %>)
<%! variables if you wnat to use outside the service method %>- This is called declaration tag

<%@ import="java.util.Date" %>- Directive tag

SpringBootApplication.run(Currentclassname.class,args);
The return type of above call is ConfigurableApplicationContext context
we can do context.getbean(classname);- This is not used in practical but we can acess the beans returned.

@Component - Using this annotation on top of a class  will create a singleton object for this class in spring container.Spring will create by itself.

@Scope(value="prototype")- using this annotation along with @component will remove the singleton behaviour, The particular classes object ie bean inside spring container will only be created if we try to create it.

@Autowire is used to connect the dependent objects- This is used while using the class. If we donot use this annotaion then we will get null pointer exception when we try to access the class or its methods

We can change the name of the object created in the spring container, ie by using @Component("lap1")
Now in spring container the name of object created will be lap1

To use a class by its name we have to use 
@Qualifier annotation 

		@Component("fooFormatter")
		public class FooFormatter implements Formatter {
		 
		    public String format() {
		        return "foo";
		    }
		}
		public class FooService {
		     
		    @Autowired
		    @Qualifier("fooFormatter")
		    private Formatter formatter;
		}

By default @Autowire searches by type  and @Qualifier searches by name;
-----------------------------------------------------------------------------------------------------------------------------------
***THE IOC CONTAINER
		
		Springs IOC container is reposible for Instantiating,Configuring and managing the dependencies between the objects.
		The org.springframework.beans and org.springframework.context packages provide the basis for the Spring Framework's IoC container

The BeanFactory interface is the central IoC container interface in Spring
		BeanFactory interface- Usually used for smaller applications(org.springframework.beans.factory.BeanFactory).
			Since these are interface we need to initialize it with its implementation
			ie for beanFactory
			Resource resource=new ClassPathResource("applicationContext.xml");  
			BeanFactory factory=new XmlBeanFactory(resource); 
			HelloWorld obj = (HelloWorld) factory.getBean("helloWorld");    
			      obj.getMessage();    
			We can have only one configuration file
			Usually, the implementations use lazy loading, which means that Beans are only instantiating when we directly calling them through the getBean() method.

		ApplicationContext Interface- ApplicationContext is a built of top of BeanFactory.For larger enterpirse applications we have to use ApplicatioContext (org.springframework.context.ApplicationContext).
			We can have multiple configuration files
			Uses eager loading, so every bean instantiate after the ApplicationContext started up.

			ApplicationContext context =   
			    new ClassPathXmlApplicationContext("applicationContext.xml"); applicationContext.xml- File name where we have define the file name

A BeanFactory pretty much just instantiates and configures beans. 
An ApplicationContext also does that, and it provides the supporting infrastructure to enable lots of enterprise-specific features such as transactions and AOP.

In short, the BeanFactory provides the configuration framework and basic functionality, while the ApplicationContext adds more enterprise-centric functionality to it.

		Resource res = new FileSystemResource("beans.xml");
		BeanFactory factory = new XmlBeanFactory(res);

		Basically that is all there is to it. Using getBean(String) you can retrieve instances of your beans; the client-side view of the BeanFactory is simple. The BeanFactory interface has just a few other methods, but ideally your application code should never use them... indeed, your application code should have no calls to the getBean(String) method at all, and thus no dependency on Spring APIs at all.

    <import> tag is used to import bean definitions from other files
    eg:
    <beans>

    <import resource="services.xml"/>
    <import resource="resources/messageSource.xml"/>
    <import resource="/resources/themeSource.xml"/>

    <bean id="bean1" class="..."/>
    <bean id="bean2" class="..."/>

</beans>
All location paths are considered relative to the definition file doing the importing, so services.xml in this case must be in the same directory or classpath location as the file doing the importingBean life cycle in Spring Bean Factory Container

		1.Bean Initialization
		2.Bean properties will be loaded and using dependency injection they will be wired
		3.WE will call the BeanNameAwares.setBeanName() and set the beanName
		4.We will call the BeanFactoryAwares.setBeanFactory() and set the bean factory
		5.WE will load the applicationcontext using ApplicationContextAwares
		5.If there is any preprocessInitialization requred that is done
		6.Init method get called specified for the bean will be called
		5 If there is any post processor initilization is required that will be done
		6.Bean is ready to use
		7.After usage the container is shutdown
		8.destory method is called 

Instantiating Beans
1.Constructor
2.For static factory method
	When defining a bean which is to be created using a static factory method, along with the class attribute which specifies the class containing the static factory method, another attribute named factory-method is needed to specify the name of the factory method itself. Spring expects to be able to call this method (with an optional list of arguments as described later) and get back a live object, which from that point on is treated as if it had been created normally via a constructor. One use for such a bean definition is to call static factories in legacy code.

	The following example shows a bean definition which specifies that the bean is to be created by calling a factory-method. Note that the definition does not specify the type (class) of the returned object, only the class containing the factory method. In this example, the createInstance() method must be a static method.

Example

<bean id="exampleBean"
      class="examples.ExampleBean2"
      factory-method="createInstance"/>


3.For non static factory method

	Instantiation using an instance factory method is where a non-static method of an existing bean from the container is invoked to create a new bean. To use this mechanism, the 'class' attribute must be left empty, and the 'factory-bean' attribute must specify the name of a bean in the current (or parent/ancestor) container that contains the instance method that is to be invoked to create the object. The name of the factory method itself must be set using the 'factory-method' attribute.

Example

<!-- the factory bean, which contains a method called createInstance() -->
<bean id="serviceLocator" class="com.foo.DefaultServiceLocator">
  <!-- inject any dependencies required by this locator bean -->
</bean>

<!-- the bean to be created via the factory bean -->
<bean id="exampleBean"
      factory-bean="serviceLocator"
      factory-method="createInstance"/>

By default the scope of Bean created in application context is singleton but the below configuration will create 2 beans
      <bean id="customer" class="jp.ne.goo.beans.Customer"> 
    <property name="custno" value="100"></property>
    <property name="custName" value="rajasekhar"> </property>
</bean>
<bean id="customer2" class="jp.ne.goo.beans.Customer"> 
    <property name="custno" value="200"></property> 
    <property name="custName" value="siva"></property> 
</bean>

	because Only one shared instance of a singleton bean is managed, and all requests for beans with an id or ids matching that bean definition result in that one specific bean instance being returned by the Spring container.


We can use another name to a bean using the alias tag

<alias name="fromName" alias="toName"/>

In this case, a bean in the same container which is named 'fromName', may also after the use of this alias definition, be referred to as 'toName'.


As a concrete example, consider the case where component A defines a DataSource bean called componentA-dataSource, in its XML fragment. Component B would however like to refer to the DataSource as componentB-dataSource in its XML fragment. And the main application, MyApp, defines its own XML fragment and assembles the final application context from all three fragments, and would like to refer to the DataSource as myApp-dataSource. This scenario can be easily handled by adding to the MyApp XML fragment the following standalone aliases:

<alias name="componentA-dataSource" alias="componentB-dataSource"/>
<alias name="componentA-dataSource" alias="myApp-dataSource" />
Now each component and the main application can refer to the dataSource via a name that is unique and guaranteed not to clash with any other definition (effectively there is a namespace), yet they refer to the same bean.


Constructor Injection

package x.y;

public class Foo {

    public Foo(Bar bar, Baz baz) {
        // ...
    }
}

<beans>
    <bean name="foo" class="x.y.Foo">
        <constructor-arg>
            <bean class="x.y.Bar"/>
        </constructor-arg>
        <constructor-arg>
            <bean class="x.y.Baz"/>
        </constructor-arg>
    </bean>
</beans>

If there is ambiguity in the type, then use
<bean id="exampleBean" class="examples.ExampleBean">
  <constructor-arg type="int" value="7500000"/>
  <constructor-arg type="java.lang.String" value="42"/>
</bean>


We can also use index

<bean id="exampleBean" class="examples.ExampleBean">
  <constructor-arg index="0" value="7500000"/>
  <constructor-arg index="1" value="42"/>
</bean>

Injecting dependencies

	The basic principle behind Dependency Injection (DI) is that objects define their dependencies (that is to say the other objects they work with) only through constructor arguments, arguments to a factory method, or properties which are set on the object instance after it has been constructed or returned from a factory method. Then, it is the job of the container to actually inject those dependencies when it creates the bean. 
	This is fundamentally the inverse, hence the name Inversion of Control (IoC), of the bean itself being in control of instantiating or locating its dependencies on its own using direct construction of classes, or something like the Service Locator pattern.

** Setter Injection vs Constructor Injection
	For mandatory dependencies use construcot injection.

	Partial dependency: can be injected using setter injection but it is not possible by constructor. ...
	Overriding: Setter injection overrides the constructor injection. 
	If we use both constructor and setter injection, IOC container will use the setter injection. Changes: We can easily change the 	value by setter injection

	Using constructor injection we cannot reconfigure a object.

Circular Dependency
	We can avoid circular dependency using setter injection by using @Lazy on the dependency.But in construcotr injection we cannot resolve circular dependency.
	
Bean dependency resolution generally happens as follows:
	The BeanFactory is created and initialized with a configuration which describes all the beans. (Most Spring users use a BeanFactory or ApplicationContext implementation that supports XML format configuration files.)
	Each bean has dependencies expressed in the form of properties, constructor arguments, or arguments to the static-factory method when that is used instead of a normal constructor. These dependencies will be provided to the bean, when the bean is actually created.

	Each property or constructor argument is either an actual definition of the value to set, or a reference to another bean in the container.
	Each property or constructor argument which is a value must be able to be converted from whatever format it was specified in, to the actual type of that property or constructor argument. By default Spring can convert a value supplied in string format to all built-in types, such as int, long, String, boolean, etc.

 *For those beans that are singleton-scoped and set to be pre-instantiated (such as singleton beans in an ApplicationContext), creation happens at the time that the container is created, but otherwise this is only when the bean is requested

 *Configuration issues like circular dependencies,reference to non existant bean will be identifed by the spring during the container loading.	This means that a Spring container which has loaded correctly can later generate an exception when you request a bean if there is a problem creating that bean or one of its dependencies. This could happen if the bean throws an exception as a result of a missing or invalid property, for example. This potentially delayed visibility of some configuration issues is why ApplicationContext implementations by default pre-instantiate singleton beans

 Cirular dependencies occur in constructor injection
 	It can be handeled or eliminated by using setter injection.


Using idref will validate the bean reference at Container deployment time

		<bean id="theTargetBean" class="..."/>

		<bean id="theClientBean" class="...">
		    <property name="targetName">
		        <idref bean="theTargetBean" />
		    </property>
		</bean>
		The above bean definition snippet is exactly equivalent (at runtime) to the following snippet:

		<bean id="theTargetBean" class="..." />

		<bean id="client" class="...">
		    <property name="targetName" value="theTargetBean" />
		</bean>

		The main reason the first form is preferable to the second is that using the idref tag allows the container to validate at deployment time that the referenced, named bean actually exists. In the second variation, no validation is performed on the value that is passed to the 'targetName' property of the 'client' bean. Any typo will only be discovered (with most likely fatal results) when the 'client' bean is actually instantiated. If the 'client' bean is a prototype bean, this typo (and the resulting exception) may only be discovered long after the container is actually deployed.

			<property name="targetName">
		   <!-- a bean with an id of 'theTargetBean' must exist; otherwise an XML exception will be thrown -->
		   <idref local="theTargetBean"/>
		</property>

Also using will  "local" Validate the bean at XML document parse time.


Using Parent will indicate that the reference Bean is in the parent context
			
			<bean id="accountService"  <-- notice that the name of this bean is the same as the name of the 'parent' bean
      class="org.springframework.aop.framework.ProxyFactoryBean">
      <property name="target">
          <ref parent="accountService"/>  <-- notice how we refer to the parent bean
      </property>
    <!-- insert other configuration and dependencies as required as here -->
</bean>

4.3.2.3 Inner beans
https://docs.spring.io/spring-framework/docs/3.0.x/spring-framework-reference/html/mvc.html#mvc-servlet

Different ways of configuring the spring application
		Configuration definition and bean definition are two different things. There are three ways to define configuration, available in Spring 4 by default:

		xml-based configuration, when you describe configuration in xml file;
		java-based configuration, when configuration is Java class, marked with specific annotations;
		groovy-based configuration, when configuration is file with Groovy code;

And there are two ways to add bean definition into application:

1.Configuration inside bean definition, when you add beans manually by declaration right in configuration.

In this case definition will be based on configuration type. For xml-config it will be <bean/> tag, for java-based config - method with @Bean annotation 

2.Annotation based bean definition, when you mark bean classes with specific annotations (like @Component, @Service, @Controller etc). This type of config uses classpath scanning.

In this case you have to specify directive for scanning classpath. For xml-config it will be <context:component-scan base-package="..."/>, for java-config -@Configuration and  @ComponentScan annotation, 

Also If we want to to use anotation and spring xml then use
<context:annotation-config/>

1.	Context:component-scan (from spring2.5 version)

This element in the spring configuration file would eliminate the need for declaring all the beans in the XML files,also there is no need to update the xml file if we are adding the new beans. Look at the below declaration in your spring configuration file.


<context:component-scan base-package="org.controller"/>

The above declaration in the spring application configuration file would scan the classes inside the specified package and create the beans instance. Note that it could create beans only if that class is annotated with correct annotations. The following are the annotations scanned by this element:

@Component
@Repository
@Service
@Controller
One advantage of this element is that it also resolve @Autowired and @Qualifier annotations. Therefore if you declare <context:component-scan>, is not necessary anymore declare <context:annotation-config> too.

2. mvc:annotation-driven

If you dont include mvc:annotation-driven also your MVC application would work if you have used the context:component-scan for creating the beans or defined the beans in your XML file. Also it supports @NumberFormat,and we can also use @RestContoller in the place of @Controller 

@RestController=@Controller+@ResponseBody

When you use the @ResponseBody annotation on a method, Spring converts the return value and writes it to the http response automatically. Each method in the Controller class must be annotated with @ResponseBody.

3. context:annotation-config
This is used to activate annotation in beans already registered in application context.That means it will resolve @Autowired and @Qualifier annotations for the beans which are already created and stored in the spring container.

**	The <context:annotation-config /> only works on beans registered within the application context. Because I removed the XML configuration for the three beans there is no bean created and <context:annotation-config /> has no "targets" to work on.

context:component-scan can also do the same job, but context:component-scan will also scan the packages for registering the beans to application context. context:annotation-config will not search for the beans registration, this will only activate the already registered beans in the context.

	**  <context:annotation-config /> can be omitted if <context:component-scan> is specified but Spring takes care of running them only once.
So bottom line If we are using <context:component-scan> then we do not have to use <context:annotation-config>
In orion we use <context:component-scan> and <context:annotation-driven>


**	can we have multiple names for one bean definition
Yes we can have multiple name for one bean , but there should be only one id for a bean deifinition and the names used for bean should be unique

eg:- <bean id="petrolBean" name="shimba,mamu,radhe" class="com.marvel.java.Petrol">
	<property name="price" value="10"></property></bean>
	<bean id="petrolBean1" name="halva" class="com.marvel.java.Petrol">
	<property name="price" value="11"></property></bean> 

**	<context-param> is used to initialize something for the whole application
<context-param>
		<param-name>contextConfigLocation</param-name>
		<param-value>/WEB-INF/applicationContext.xml</param-value>
	</context-param>
**	<init-param> will be used if you want to initialize some parameter for a particular servlet. When request come to servlet first its init method will be called then doGet/doPost
<servlet>
		<servlet-name>mvc-dispatcher</servlet-name>
		<servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>

		<init-param>
			<param-name>contextConfigLocation</param-name>
			<param-value>classpath:/META-INF/spring/applicationContext-servlet.xml</param-value>
		</init-param>

		<load-on-startup>1</load-on-startup>
	</servlet>


**	@Component – generic and can be used across application.
**	@Service – annotate classes at service layer level.
**	@Controller – annotate classes at presentation layers level, mainly used in Spring MVC.
**	@Repository – annotate classes at persistence layer, which will act as database repository.

** @Component vs @Bean

		@Component is used for component scanning and autowiring


		When should you use @Bean?

		Sometimes automatic configuration is not an option. When? Let's imagine that you want to wire components from 3rd-party libraries (you don't have the source code so you can't annotate its classes with @Component), so automatic configuration is not possible.

		The @Bean annotation returns an object that spring should register as bean in application context. The body of the method bears the logic responsible for creating the instance.

		@Bean is used above the method and @Component is used in the class


**	 @Auotwired vs @Resource
			1.@Autowired is a spring annotation and @Resource is specified by JSR-250 ie java annotation.
			2.@Autowired + @Qualifier will work only with spring DI, if you want to use some other DI in future @Resource is 			good option

		JSRs are Java Specification Requests, basically change requests for the Java language, libraries and other components.
		It's all part of the Java Community Process, whereby interested parties can put forward their ideas for enhancements and (hopefully) have them taken up and acted upon


	*********************************	Dispacther Servlet (it extends HttpServlet )   *************************************

DispatcherServlet acts as front controller  which receives the request and delegates in to the other component. 
The DispatcherServlet  provides a single entry point for a client request to Spring MVC web application and forwards request to Spring MVC controllers for processing.

Each DispatcherServlet has its own WebApplicationContext, which inherits all the beans already defined in the root WebApplicationContext. These inherited beans defined can be overridden in the servlet-specific scope, and you can define new scope-specific beans local to a given servlet instance.

		Dispactherservlet is defined in the web.xml and it will be loaded on startup,
		we dont have to create the context manually
		We dont have to create or destory the webapplicationContext for the dispatcherservlet, it will be created during the 			server startup and destroyed during the server stop .

				Consider the following DispatcherServlet servlet configuration (in the web.xml file):

				<web-app>

				    <servlet>
				        <servlet-name>golfing</servlet-name>
				        <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>
				        <load-on-startup>1</load-on-startup>
				    </servlet>

				    <servlet-mapping>
				        <servlet-name>golfing</servlet-name>
				        <url-pattern>/golfing/*</url-pattern>
				    </servlet-mapping>

				</web-app>

		*With the above servlet configuration in place, you will need to have a file called /WEB-INF/golfing-servlet.xml in your application; this file will contain all of your Spring Web MVC-specific components (beans).


		as per the above example the file /golfing-servlet.xml will have a tag called component-scan where we will give the base packages , so in this package  if there is any class with @Component or @Contrller those will be registered in the webapplicationContext

		WebApplicationnContext is an extension of APPlicationContext.
		It has some additional features which are required for web applications.
		It knows which servlet it is linked with because of servletcontext.

	The DispatcherServlet uses HandlerMapping implementations -  to route incoming requests to handler objects. By default, it uses 	BeanNameUrlHandlerMapping and DefaultAnnotationHandlerMapping, which is driven by @RequestMapping annotation.
	DispatcherServlet scans the class path.

	DispatcherServlet uses special beans to processRequests and render appropriate views
	 These beans are part of Spring Framework. You can configure them in the WebApplicationContext, just as you configure any other bean

These are the beans.

	 controllers-Form the C part of the MVC.

	handler mappings-Handle the execution of a list of pre-processors and post-processors and controllers that will be executed if they match certain criteria (for example, a matching URL specified with the 	controller).

	view resolvers-			Resolves view names to views.

	locale resolver-		A locale resolver is a component capable of resolving the locale a client is using, in order to be able to offer internationalized views

	Theme resolver-			A theme resolver is capable of resolving themes your web application can use, for example, to offer personalized layouts

	multipart file resolver-	Contains functionality to process file uploads from HTML forms.

	handler exception resolvers-	Contains functionality to map exceptions to views or implement other more complex exception handling code.

When a request comes to a DispatcherServlet

1.The webapplicationContext is searched and bound to the request as a attribute so that controllers and other elements can use it.
	It is bound by default under the key DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE.

2.The locale resolver is bound to the request to enable elements in the process to resolve the locale to use when processing the request (rendering the view, preparing data, and so on). If you do not need locale resolving, you do not need it.

3.The theme resolver is bound to the request to let elements such as views determine which theme to use. If you do not use themes, you can ignore it.

4.If you specify a multipart file resolver, the request is inspected for multiparts; if multiparts are found, the request is wrapped in a MultipartHttpServletRequest for further processing by other elements in the process. (See Section 15.8.2, “Using the MultipartResolver” for further information about multipart handling)

5.An appropriate handler is searched for. If a handler is found, the execution chain associated with the handler (preprocessors, postprocessors, and controllers) is executed in order to prepare a model or rendering.

6.If a model is returned, the view is rendered. If no model is returned, (may be due to a preprocessor or postprocessor intercepting the request, perhaps for security reasons), no view is rendered, because the request could already have been fulfilled.

Read more: https://javarevisited.blogspot.com/2017/09/dispatcherservlet-of-spring-mvc-10-points-to-remember.html#ixzz5vmyB0kT8

	 It is inherited from javax.servlet.http.HttpServlet, it is typically configured in the web.xml file.

	A web application can define any number of DispatcherServlet instances. Each servlet will operate in its own namespace, loading its own application context with mappings, handlers, etc.In most cases, applications have only single DispatcherServlet with the context-root URL(/), that is, all requests coming to that domain will be handled by it.

DispatcherServlet uses Spring configuration classes to discover the delegate components it needs for request mapping, view resolution, exception handling etc.

A Front Controller is a common pattern in web application and used to receive request and delegate to other components in the application for actual processing. 
eg:-
<servlet>
		<servlet-name>mvc-dispatcher</servlet-name>
		<servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>

		<init-param>
			<param-name>contextConfigLocation</param-name>
			<param-value>classpath:/META-INF/spring/applicationContext-servlet.xml</param-value>
		</init-param>

		<load-on-startup>1</load-on-startup>
	</servlet>

	<servlet-mapping>
		<servlet-name>mvc-dispatcher</servlet-name>
		<url-pattern>/</url-pattern>
	</servlet-mapping>
	In the above xml configuration we define a Dispatched servelt and <init-param> is used to initialize the applicationContext-servlet.xml file which has <compoment scan> for the defined base packages

	ie <context:component-scan base-package="com.infomatics.orion.web" />
	and Under servlet-mapping we give a url patter so that al the url will go through dispatecher servlet which is the front controller of spring application
	
** What are Servlet Filters?
	Servlet filters are, in general, a Java WebApp concept. You can have servlet filters in any webapp, whether or not you use Spring framework in your application.

	These filters can intercept requests before they reach the target servlet. You can implement common functionality, like authorization, in servlet filters. Once implemented, you can configure the filter in your web.xml to be applied to a specific servlet, specific request url patterns or all url patterns.

** Where servlet filters are used?
	Modern web-apps can have dozens of such filters. Things like authorization, caching, ORM session management, and dependency injection are often implemented with the aid of servlet filter. All of these filters need to be registered in web.xml.

** Instantiating Servlet Filters - without Spring Framework
	Your servlet container creates instances of Filters declared in web.xml and calls them at appropriate times (i.e., when servicing servlet requests). 
	DelegatingFilterProxy, so that Spring creates your filter instances,This is where DelegatingFilterProxy steps in.

 	DelegatingFilterProxy is an implementation of the javax.servlet.Filter interface provided by Spring Framework.

  	Once you configure DelegatingFilterProxy in web.xml, you can declare the actual beans that do the filtering in your spring configuration. This way, Spring creates the instances of beans that do the actual filtering, and you can use DI to configure these beans.

	Note that you need only a single DelegatingFilterProxy declaration in web.xml but you can have several filtering beans chained together in your application context.

** Cors- Cross Origin Resource Sharing 
	way to manage requests from different domains
	This cross-origin sharing standard is used to enable cross-site HTTP requests.

		@CrossOrigin(maxAge = 3600)
		@RestController
		@RequestMapping("/account")
		public class AccountController {
		
		    @CrossOrigin("http://example.com")
		    @RequestMapping(method = RequestMethod.GET, "/{id}")
		    public Account retrieve(@PathVariable Long id) {
		        // ...
		    }
		
		    @RequestMapping(method = RequestMethod.DELETE, path = "/{id}")
		    public void remove(@PathVariable Long id) {
		        // ...
		    }
		}

		Spring will combine attributes from both annotations to create a merged CORS configuration.

		Here, both methods will have a maxAge of 3,600 seconds, the method remove() will allow all origins, and the method 			retrieve() will only allow origins from http://example.com.

Global CORS Configuration

	As an alternative to the fine-grained annotation-based configuration, Spring lets us define a global CORS configuration out of 		our controllers. This is similar to using a Filter-based solution but can be declared within Spring MVC and combined with a 		fine-grained @CrossOrigin configuration.

			@Configuration
			@EnableWebMvc
			public class WebConfig implements WebMvcConfigurer {
			
			    @Override
			    public void addCorsMappings(CorsRegistry registry) {
			        registry.addMapping("/**");
			    }
			}

	Also, you can add information to instruct browser to allow only certain HTTP methods (GET/PUT/POST/DELETE etc) on those domain URLs.

CORS With Spring Security
	If we use Spring Security in our project, we must take an extra step to make sure it plays well with CORS. That’s because CORS 		needs to be processed first. Otherwise, Spring Security will reject the request before it reaches Spring MVC
	
	Something like this
			@EnableWebSecurity
			public class WebSecurityConfig {
			
			    @Bean
			    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {
			        http.cors().and()...
			    }
			}

** Response Headers of CorsFilter
		1.Access-Control-Allow-Origin:specifies the authorized domains to make cross-domain request. Use “*” as value if there is no restrictions.
		2.Access-Control-Allow-Credentials : specifies if cross-domain requests can have authorization credentials or not.
		Access-Control-Allow-Methods : indicates the methods allowed when accessing the resource.

	 response.addHeader("Access-Control-Allow-Origin", "http://127.0.0.1:9000");
		 response.addHeader("Access-Control-Allow-Credentials", "true");

We can configure CORS to override the default Spring Security CORS handling. For that, we need to add a CorsConfigurationSource bean that takes care of the CORS configuration using a CorsConfiguration instance. The http.cors() method uses CorsFilter if a corsFilter bean is added, else it uses CorsConfigurationSource. If neither is configured, then it uses the Spring MVC pattern inspector handler

			@Bean
			CorsConfigurationSource corsConfigurationSource() {
			    CorsConfiguration configuration = new CorsConfiguration();
			    configuration.setAllowedOrigins(Arrays.asList("*"));
			    configuration.setAllowedMethods(Arrays.asList("*"));
			    configuration.setAllowedHeaders(Arrays.asList("*"));
			    UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
			    source.registerCorsConfiguration("/**", configuration);
			    return source;
			}
		
   ** OncePerRequestFilter makes sure of it that this authentication process happens only once

**Microservices

	They are independent spring boot applications which run to achive a task

	Using RestTemplate we can make a api call to another spring boot in order to achieve micro services.
	In futhure RestTemplate will be depricated and we have to use webclient which is from Reactive web.

	RestTemplate is thread safe
	RestTemplate restTemplate = new RestTemplate();
	Movie movie=restTemplate.getForObject("http://localhost:8081/movies"+movieId,Movies.class);

	WebClient.Builder builder=WebClient.builder();
	Movie movie=builder.build().get().uri("http://localhost:8081/movies"+movieId).retrieve().bodyToMono(Movie.class).block();

	bodyToMono is like a promise , You will not get it now but u have to wait. It is a Reactive web concept.

	we use block() because we are blocking the execution until the value is received.

	For post request use post() 

	** To change the port number if tomcat in  spring boot 
	go to application.properties of ser/resource folder and type server.port=8081

** Spring modules

		1.Spring core
			The Core is the Ioc container is responsible for Instantiating,Configuring and managing the dependencies between 			the objects.
			It give the features like dependency Injection and Inversion of Control.
			The context module present in the spring core will make the object or beans created in the container available 				for our use.

		2.Spring web- Spring web consists of servlets
					Spring web has mvc framework,
					It provides multipart file Upload functionality.

		3.Data Access/Integration- Has JDBC and ORM -eg Hibernate.

		4.Spring AOP- Aspect Oriented Programming

		5.Spring Instrumentation

		6.Spring test-The Test module contains the Test Framework that supports testing Spring components using JUnit or TestNG

**Mongodb Configuration in applicationContext-dao.xml file

<mongo:mongo-client id="mongoDB" host="${mongo.host}"
		port="${mongo.port}" />
	<mongo:db-factory id="mongoDbFactory" dbname="${mongo.dbname}"
		mongo-ref="mongoDB" />
	<mongo:mapping-converter id="converter" />
	<bean name="gridFsTemplate"
		class="org.springframework.data.mongodb.gridfs.GridFsTemplate">
		<constructor-arg ref="mongoDbFactory" />
		<constructor-arg ref="converter" />
	</bean>

and we can perform curd operations using MongoRepository creating a interface that extends MongoRepository

** Configuring datasource 

In Tomcat context.xml
<Resource auth="Container" driverClassName="com.mysql.jdbc.Driver" maxActive="50" maxIdle="30" maxWait="10000" 
name="jdbc/orionDataSource" password="orion123" type="javax.sql.DataSource" url="jdbc:mysql://localhost:3306/orion_db" username="root"/>

And in applicationContext.xml of orion_dao add

<jee:jndi-lookup id="dataSource" jndi-name="jdbc/orionDataSource"
		resource-ref="true" lookup-on-startup="true" />


For using entityManager,We had 
<bean
		class="org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean"
		id="entityManagerFactory">
		<property name="dataSource" ref="dataSource" />
	</bean>

<tx:annotation-driven transaction-manager="transactionManager" />

Hence using
@PersistanceContext
EntityManager entityManager in BaseDao
we where able to execute queries

eg:
@Override
	public List<Backofficeemployee> getActiveBackofficeemployee() {
		String activeBackofficeemployee = "SELECT boe FROM Backofficeemployee as boe where boe.boeallowLogin = true and boe.boeuserType = 1";
		TypedQuery<Backofficeemployee> q1 = entityManager.createQuery(activeBackofficeemployee,
				Backofficeemployee.class);

		return q1.getResultList();
	}

**	Design Pattern

	Proxy Design Pattern - Proxy means 'on behalf of' or 'representing'
	Proxy is a object used by the client to access the real Object 
	This is mainly done for security reasons
	eg: 1.Role based Access
		2.Proxy server are used to check block certain sites in companies.
		3. @Transactional also creates Proxy object of Transaction

	Type Of Proxy
	1.Remote Proxy
	2.Virtual Proxy

Database vs Schema
	Depends on the database server. MySQL doesn't care, its basically the same thing.

	Oracle, DB2, and other enterprise level database solutions make a distinction. Usually a schema is a collection of tables and a Database is a collection of schemas.

Hibernate

**Dialect class is java class, which contains code to map between java language data type database data type.
	In Hibernate-cfg.xml
		<hibernate-configuration>
		   <session-factory>
		       <property name="hibernate.connection.driver_class">com.mysql.jdbc.Driver</property>
		       <property name="hibernate.connection.password">orion123</property>
		       <property name="hibernate.connection.url">jdbc:mysql://localhost:3306/orion_db</property>
		       <property name="hibernate.connection.username">root</property>
		       <property name="hibernate.default_schema">orion_db</property>
		       <property name="hibernate.dialect">org.hibernate.dialect.MySQLDialect</property>
		   </session-factory>
		</hibernate-configuration>

States of Hibernate Objects

1.Transcient State- It is a state of the object before its given to hibernate to save in the database .
2.Persistant- This is state where the object is given to hibernate to handel or to save in the database
3.Detached is a state similar to transcient , once the session is closed the object becomes detached

when we do session.delete(user) object goes from persistant to transcient state

To update a object only if any changes are made then we need to add @ori.hibernate.annotations.Entity(SelectBeforeUpdate=true) below the entity annotation of pojo class. This means we are telling hibernate to run a select to check the data in database before updating

SessionFactory vs session

SessionFactory is common for one application and it is thread Safe, it uses second level caching

Session is used to perform curd operations and it is not thread safe , it uses first level caching

Caching in hibernate
we have 
1st level caching
2nd level caching eg ehcaching

By default first level caching is enabled by hibernate
 to enable second level cache we have to download the required second level cash through pom.xml
 and set second level cache to true and mention the provider in hibernate.cfg.xml file
 and use @2 anotations in the entity class

Get vs load
Only use load() method if you are sure that the object exists.
If you are not sure that the object exist, then use one of get() methods.

load will not hit the database if we donot use the object and it gives ur proxy object it will only give the object when we use it
load will throw object not found exception

get will hit the database and it will give us real object and if there is not object it will give null

Object Locking
read this https://stackoverflow.com/questions/129329/optimistic-vs-pessimistic-locking
JPA by default uses Optimistic locking

When dealing with conflicts, you have two options:

You can try to avoid the conflict, and that's what Pessimistic Locking does.
Or, you could allow the conflict to occur, but you need to detect it upon committing your transactions, and that's what Optimistic Locking does.

Pessimistic locking
	Pessimistic locking achieves this goal by taking a shared or read lock on the account so Bob is prevented from changing the 		account.
	both Alice and Bob will acquire a read lock on the account table row that both users have read. The database acquires these 		locks on SQL Server when using Repeatable Read or Serializable.
	Because both Alice and Bob have read the account with the PK value of 1, neither of them can change it until one user releases 		the read lock. This is because a write operation requires a write/exclusive lock acquisition, and shared/read locks prevent 		write/exclusive locks.

	Only after Alice has committed her transaction and the read lock was released on the account row, Bob UPDATE will resume and 		apply the change. Until Alice releases the read lock, Bob's UPDATE blocks.

	Is when you lock the record for your exclusive use until you have finished with it. It has much better integrity than optimistic 	locking but requires you to be careful with your application design to avoid Deadlocks. To use pessimistic locking you need 		either a direct connection to the database (as would typically be the case in a two tier client server application) or an 		externally available transaction ID that can be used independently of the connection.

	In the latter case you open the transaction with the TxID and then reconnect using that ID. The DBMS maintains the locks and 		allows you to pick the session back up through the TxID. This is how distributed transactions using two-phase commit protocols 		(such as XA or COM+ Transactions) work

	Pessimistic locking assumes that concurrent transactions will conflict with each other, and requires resources to be locked 		after they are read and only unlocked after the application has finished using the data.

	When we use Pessimistic Locking in a transaction, and access an entity, it'll be locked immediately. The transaction releases 		the lock either by committing or rolling back the transaction.

	When using Pessimistic Locking, the database will try to lock the entity immediately. The underlying JPA implementation throws a 	LockTimeoutException when the lock can't be obtained immediately. To avoid such exceptions, we can specify the lock timeout 		value.
	
	In Spring Data JPA, the lock timeout can be specified using the QueryHints annotation by placing a QueryHint on query methods:

	@Lock(LockModeType.PESSIMISTIC_READ)
	@QueryHints({@QueryHint(name = "javax.persistence.lock.timeout", value = "3000")})
	public Optional<Customer> findById(Long customerId);

	To enforce the lock on predefined repository methods, such as findAll or findById(id), we have to declare the method within the 	repository and annotate the method with the Lock annotation:
	@Lock(LockModeType.PESSIMISTIC_WRITE)
	public Optional<Customer> findById(Long customerId);

Optimistic Locking
	Optimistic Locking allows the conflict to occur but detects it upon applying Alice's UPDATE as the version has changed.
	This time, we have an additional version column. The version column is incremented every time an UPDATE or DELETE is executed, 		and it is also used in the WHERE clause of the UPDATE and DELETE statements. For this to work, we need to issue the SELECT and 		read the current version prior to executing the UPDATE or DELETE, as otherwise, we would not know what version value to pass to 	the WHERE clause or to increment

	Is a strategy where you read a record, take note of a version number (other methods to do this involve dates, timestamps or 		checksums/hashes) and check that the version hasn't changed before you write the record back. When you write the record back you 		filter the update on the version to make sure it's atomic. (i.e. hasn't been updated between when you check the version 	and write the record to the disk) and update the version in one hit.

	If the record is dirty (i.e. different version to yours) you abort the transaction and the user can re-start it.We will get 		OptimisticLockException

	This strategy is most applicable to high-volume systems and three-tier architectures where you do not necessarily maintain a 		connection to the database for your session. In this situation the client cannot actually maintain database locks as the 		connections are taken from a pool and you may not be using the same connection from one access to the next

	Optimistic locking assumes that multiple transactions can complete without affecting each other, and that therefore transactions 	can proceed without locking the data resources that they affect. Before committing, each transaction verifies that no other 		transaction has modified its data. If the check reveals conflicting modifications, the committing transaction rolls back[1]. We 	will get OptimisticLockException

	In Optimistic Locking, the transaction doesn't lock the entity immediately. Instead, the transaction commonly saves the entity's 	state with a version number assigned to it.
	
	When we try to update the entity's state in a different transaction, the transaction compares the saved version number with the 	existing version number during 	the update.

	At this point, if the version number differs, it means that we can't modify the entity. If there's an active transaction, then 		that transaction will be rolled back and the underlying JPA implementation will throw an OptimisticLockException.

	For Entity class we can use @Version annotation to any field and Jpa will automatically take care of optimistic locking
	
	To specify a lock on a custom query method of a Spring Data JPA repository, we can annotate the method with @Lock and specify 		the required lock mode type:

	@Lock(LockModeType.OPTIMISTIC_FORCE_INCREMENT)
	@Query("SELECT c FROM Customer c WHERE c.orgId = ?1")
	public List<Customer> fetchCustomersByOrgId(Long orgId);
	
	To enforce the lock on predefined repository methods, such as findAll or findById(id), we have to declare the method within the 	repository and annotate the method with the Lock annotation:
	@Lock(LockModeType.PESSIMISTIC_WRITE)
	public Optional<Customer> findById(Long customerId);
	
	When the lock is explicitly enabled, and there's no active transaction, the underlying JPA implementation will throw a 			TransactionRequiredException.

	If the lock can't be granted, and the locking conflict doesn't result in a transaction rollback, JPA throws a 				LockTimeoutException, but it doesn't mark the active transaction for rollback.
	
	When the transaction needs to strictly adhere to ACID rules, we should use Pessimistic Locking. 
	Optimistic Locking should be applied when we need to allow multiple concurrent reads and when eventual consistency is acceptable 	within the application context.

**Transaction 
	A transaction is a unit of work with few steps performed by a data base management system against a database
	They are all or nothing ie either all the steps should be completed or al the steps should be rolled back
	Transaction should take care of Acid Properties
	A- Atomicity- Ensure that all the steps are successful or all of them fail
	C- Consistant-The system should be left in a consistent state if either on success or failure
	I-Isolation- Multiple users should be able to work without any issue ie concurent read or writes
	D-After the sucessful operation the data shoudl be stored permentaly.

ACID properties: Atomicity, Consistency, Isolation, and Durability.
**	SPRING TRANSACTION
Spring 3.1 introduces the @EnableTransactionManagement annotation that we can use in a @Configuration class to enable transactional support:
 if we're using a Spring Boot project and have a spring-data-* or spring-tx dependencies on the classpath, then transaction management will be enabled by default
 
@Transactional
	The annotation supports further configuration as well:

	the Propagation Type of the transaction
	the Isolation Level of the transaction
	a Timeout for the operation wrapped by the transaction
	a readOnly flag – a hint for the persistence provider that the transaction should be read only
	the Rollback rules for the transaction
	
	Note that by default, rollback happens for runtime, unchecked exceptions only. The checked exception does not trigger a rollback of the transaction. We can, of course, configure this behavior with the rollbackFor and noRollbackFor annotation parameters.

	At a high level, Spring creates proxies for all the classes annotated with @Transactional, either on the class or on any of the methods. The proxy allows the framework to inject transactional logic before and after the running method, mainly for starting and committing the transaction.
	
	if the transactional bean is implementing an interface, by default the proxy will be a Java Dynamic Proxy. This means that only external method calls that come in through the proxy will be intercepted. Any self-invocation calls will not start any transaction, even if the method has the @Transactional annotation.

	Another caveat of using proxies is that only public methods should be annotated with @Transactional. Methods of any other visibilities will simply ignore the  annotation silently as these are not proxied

 	Spring wraps your bean in the proxy, your bean has no knowledge of it. Only calls from "outside" your bean go through the proxy.
	We are using in service layer on top of each method.
	Spring will create a wrapper method and that method will begin and commit the transaction

Transaction Propagation
	
	@Transactional(propagation = Propagation.REQUIRED)
		REQUIRED is the default propagation. Spring checks if there is an active transaction, and if nothing exists, it creates 		a new one. Otherwise, the business logic appends to the currently active transaction:
		
	@Transactional(propagation = Propagation.SUPPORTS)
		For SUPPORTS, Spring first checks if an active transaction exists. If a transaction exists, then the existing 				transaction will be used. If there isn't a transaction, it is executed non-transactional:
	
	@Transactional(propagation = Propagation.MANDATORY)
		When the propagation is MANDATORY, if there is an active transaction, then it will be used. If there isn't an active 			transaction, then Spring throws an exception:
	
	@Transactional(propagation = Propagation.NEVER)
		For transactional logic with NEVER propagation, Spring throws an exception if there's an active transaction:
	
	@Transactional(propagation = Propagation.NOT_SUPPORTED)
		If a current transaction exists, first Spring suspends it, and then the business logic is executed without a transaction:
	
	@Transactional(propagation = Propagation.REQUIRES_NEW)
		When the propagation is REQUIRES_NEW, Spring suspends the current transaction if it exists, and then creates a new one:

Isolation Management in Spring https://www.youtube.com/watch?v=-gxyut1VLcs&t=252s
	
Transaction Isolation and Voilations
	
	Isolation is one of the common ACID properties: Atomicity, Consistency, Isolation, and Durability. Isolation describes how 		changes applied by concurrent transactions are visible to each other.

	Each isolation level prevents zero or more concurrency side effects on a transaction:

Voilations
READ_UNCOMMITTED(Dirty read): read the uncommitted change of a concurrent transaction
	
		If T1 transaction reads data from table A1 that was written by another concurrent transaction T2. If on the way T2 is 		rollback, the data obtained by T1 is invalid one. E.g. a=2 is original data. If T1 read a=1 that was written by T2. If T2 		rollback then a=1 will be rollback to a=2 in DB. But, now, T1 has a=1 but in DB table it is changed to a=2.
		
		Postgres does not support READ_UNCOMMITTED isolation and falls back to READ_COMMITED instead. Also, Oracle does not 			support or allow READ_UNCOMMITTED.

Nonrepeatable read: If Transaction T1 reads a value from a field and after reading if another Transaction T2 updates the field with different value , then if again Transaction T1 reads the same value , it gets different value on re-read of a field. 
	
		 If T1 transaction reads data from table A1. If another concurrent transaction (T2) update data on table A1. Then the 			data that T1 has read is different from table A1. Because T2 has updated the data on table A1. 
		E.g. if T1 read a=1 and T2 updated a=2. Then a!=b.
		 
		 READ_COMMITTED is the default level with Postgres, SQL Server, and Oracle.
		 REPEATABLE_READ does not allow simultaneous access to a row at all. Hence the lost update can't happen
	
Phantom read: get different rows after re-execution of a range query if another transaction adds or removes some rows in the range and commits
	
		 If T1 transaction reads data from table A1 with certain number of rows. If another concurrent transaction (T2) inserts 		more rows on table A1. The number of rows read by T1 is different from rows on 	table A1.

Isolation Levels	
We can set the isolation level of a transaction by @Transactional::isolation. It has these five enumerations in Spring: DEFAULT, READ_UNCOMMITTED, READ_COMMITTED, REPEATABLE_READ, SERIALIZABLE.
	
DEFAULT: The default isolation level is DEFAULT. As a result, when Spring creates a new transaction, the isolation level will be 		the default isolation of our RDBMS

ReadUncommitted: Transaction B can read uncommitted data from Transaction A and it could see different rows based on B writing. 			No lock at all- This will have all the 3 Voilations (READ_UNCOMMITTED,Nonrepeatable read, Phanton Read)
	
ReadCommitted: Transaction B can read ONLY committed data from Transaction A and it could see different rows based on COMMITTED 			only B writing. could we call it Simple Lock?- This will have 2 Voilations (Nonrepeatable read, Phanton Read)

RepeatableRead: Transaction B will read the same data (rows) whatever Transaction A is doing. But Transaction A can change other 			rows. Rows level Block- This will have 1 Voilations ( Phanton Read)
	
ISOLATION_SERIALIZABLE : Transaction B will read the same rows as before and Transaction A cannot read or write in the table. 					 Table-level Block-This will have no Voilations (Nonrepeatable read, Phanton Read)
	 
	ISOLATION_SERIALIZABLE: Scenario 1, Scenario 2, Scenario 3 never happen. It is complete isolation. It involves full locking. It 	affects performace because of locking.
		
	SERIALIZABLE is the highest level of isolation. It prevents all mentioned concurrency side effects, but can lead to the 			lowest concurrent access rate because it executes concurrent calls sequentially.

In other words, concurrent execution of a group of serializable transactions has the same result as executing them in serial.

RollBack
	By Default transaction will be rolled back for runtime exceptions, For Unchecked exceptions we can use rollBackfor or rollBackForClass attribute,
	
	@Transactional(rollbackFor = MyCheckedException.class)
	public void foo() {
   	 throw new RuntimeException();    
	}

	In the above case transaction will be rolledback even for checked exceptions

**	EntityManager
	 is used to interact with Database we can add,update or delete a record in database
	To use entitymaneger we have to use entitymanagerfactorybean to get the entitymanagerobject

		In Orion we use 
		<bean
				class="org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean"
				id="entityManagerFactory">
				<property name="dataSource" ref="dataSource" />
			</bean>
		as entityManagerFactory	 in applicationcontext.xml


		Persist will save the data in database and also we can make future update if we are making any change
		Merge wll save the data but If we want to update then again we have to call merge

		MyEntity e = new MyEntity();

		// scenario 1
		// tran starts
		em.persist(e); 
		e.setSomeField(someValue); 
		// tran ends, and the row for someField is updated in the database

		// scenario 2
		// tran starts
		e = new MyEntity();
		em.merge(e);
		e.setSomeField(anotherValue); 
		// tran ends but the row for someField is not updated in the database
		// (you made the changes *after* merging)

**EntityManager vs Session
		EntityManager is a standardized api of jpa
		Session is a hibernate specific api

		EntityManager is a adopter class which wraps a session

			We can get seesion object from entityManager

			Session session = entityManager.unwrap(Session.class);

JPA is a specification it is not a implementation 

Hibernate vs Soring Data jpa

	Hibernate is a JPA implementation.
	Spring Data JPA is a JPA data access abstraction. Spring Data JPA cannot work without a JPA provider.

	Spring Data offers a solution to the DDD Repository pattern or the legacy GenericDao custom implementations. It can also 		generate JPA queries on your behalf through method name conventions.

	With Spring Data, you may use Hibernate, EclipseLink, or any other JPA provider. A very interesting benefit of using Spring or 		Java EE is that you can control transaction boundaries declaratively using the @Transactional annotation.

	Spring JDBC is much more lightweight, and it's intended for native querying, and if you only intend to use JDBC alone, then you 	are better off using Spring JDBC to deal with the JDBC verbosity.

	Therefore, Hibernate and Spring Data are complementary rather than competitors.

Let's say you are using spring + hibernate for your application. Now you need to have dao interface and implementation where you will be writing crud operation using SessionFactory of hibernate. Let say you are writing dao class for Employee class, tomorrow in your application you might need to write similiar crud operation for any other entity. So there is lot of boilerplate code we can see here.Now Spring data jpa allow us to define dao interfaces by extending its repositories(crudrepository, jparepository) so it provide you dao implementation at runtime. You don't need to write dao implementation anymore.Thats how spring data jpa makes your life easy.

JpaRepository vs CrudRepository

	JpaRepository extends PagingAndSortingRepository which in turn extends CrudRepository.

	Their main functions are:

	CrudRepository mainly provides CRUD functions.

	PagingAndSortingRepository provides methods to do pagination and sorting records.

	JpaRepository provides some JPA-related methods such as flushing the persistence context and deleting records in a batch.
	Because of the inheritance mentioned above, JpaRepository will have all the functions of CrudRepository and PagingAndSortingRepository. So if you don't need the repository to have the functions provided by JpaRepository and PagingAndSortingRepository , use CrudRepository.

postgres vs MYSQL
Postgres is an object-relational database, while MySQL is a purely relational database. This means that Postgres includes features like table inheritance and function overloading, which can be important to certain applications. Postgres also adheres more closely to SQL standards.
Postgres has better performance and scalability
MVCC enables simultanious Read and write operations in case of postgres
Postgres handles concurrency better than MySQL for multiple reasons:
	Postgres implements Multiversion Concurrency Control (MVCC) without read locks Postgres supports parallel query plans that can use multiple CPUs/cores Postgres can create indexes in a non-blocking way (through the CREATE INDEX CONCURRENTLY syntax).
	
	
Postgres is known for protecting data integrity at the transaction level. This makes it less vulnerable to data corruption.

MYSQL can be used for small webapplications

-----------------------------------------------------------------------------------------------------------------------------------
Sql vs Nosql database

Nosql database
1.Insertion and retrieval is eifficient since there are no joins required
2.Schema is easily changable- We alter the schema without effecting the exisiting records ie its easier
3.Built for scalability or sharding or horizontal partition
4.These systems are build for aggregation ie to get the intelligent data

Disadvantage
1.update=delete+insert ie updates are not nice or easy means ACID is not guarented
2.Relational constraint is not possible
3.Joining is also not efficient

Mongodb stores the data in BSON format- Binary JSON

---------------------------------------------------------------------------------------
JPA Topics

spring.jpa.hibernate.ddl-auto

	For the record, the spring.jpa.hibernate.ddl-auto property is Spring Data JPA specific and is their way to specify a value that will eventually be passed to Hibernate under the property it knows, hibernate.hbm2ddl.auto

	The update operation for example will attempt to add new columns, constraints, etc but will never remove a column or constraint that may have existed previously but no longer does as part of the object model from a prior run.

	In production, it's often highly recommended you use none or simply don't specify this property. That is because it's common practice for DBAs to review migration scripts for database changes, particularly if your database is shared across multiple services and applications

spring.jpa.hibernate.naming.physical-strategy
Physical Naming Strategy 
	Will tell JPA to create columns how we have defined rather than using its own ways to create
		eg: employeeName -> jpa will create it as employee_name.

Spring Boot configure and use two data sources

	#first db
	spring.datasource.url = [url]
	spring.datasource.username = [username]
	spring.datasource.password = [password]
	spring.datasource.driverClassName = oracle.jdbc.OracleDriver

	#second db ...
	spring.secondDatasource.url = [url]
	spring.secondDatasource.username = [username]
	spring.secondDatasource.password = [password]
	spring.secondDatasource.driverClassName = oracle.jdbc.OracleDriver


Add in any class annotated with @Configuration the following methods:

	@Bean
	@Primary
	@ConfigurationProperties(prefix="spring.datasource")
	public DataSource primaryDataSource() {
	    return DataSourceBuilder.create().build();
	}

	@Bean
	@ConfigurationProperties(prefix="spring.secondDatasource")
	public DataSource secondaryDataSource() {
	    return DataSourceBuilder.create().build();
	}

	and Create seperate Entitymanager and TransactionManager

		refer this https://www.baeldung.com/spring-data-jpa-multiple-databases

JPA does not support aggregate functions like average,sum etc
	eg fingByAgeBetween(int min,int mx)// this will work

	but findByAgeAverage()//this will not work

GROUP BY
	The GROUP BY statement groups rows that have the same values into summary rows, like "find the number of customers in each country".

	The GROUP BY statement is often used with aggregate functions (COUNT(), MAX(), MIN(), SUM(), AVG()) to group the result-set by one or more columns.

Pagination and Sorting

	pagination
	
		List<Product> findAllByPrice(double price, Pageable pageable);

		Pageable firstPageWithTwoElements = PageRequest.of(0, 2);

		Pageable secondPageWithFiveElements = PageRequest.of(1, 5);

	Sorting

		Page<Product> allProductsSortedByName = productRepository.findAll(Sort.by("name"));

	Both Sorting and Pagination

		Pageable sortedByName = PageRequest.of(0, 3, Sort.by("name"));

